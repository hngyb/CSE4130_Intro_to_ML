{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(int('0xC0FFEE', 16))\n",
    "np.random.seed(int('0xC0FFEE', 16))\n",
    "PI = math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy data load\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### np.savez('./filename.npz', x=X, y=Y)\n",
    "\n",
    "practice1_data = np.load('./practice1_data.npz')\n",
    "print(f'Check key values: {practice1_data.files}')\n",
    "X, Y = practice1_data['x'], practice1_data['y']\n",
    "print(X.shape, Y.shape)\n",
    "print(X[0:10], Y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 1\n",
    "평균, 시그마가 정해진 두 개의 클래스에서 1차원 데이터를 샘플링해서, 히스토그램과 확률분포 함수를 각각 그려보시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_histogram(A, B):\n",
    "    plt.hist(A, label='a', alpha=0.5)\n",
    "    plt.hist(B, label='b', alpha=0.5)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_histogram(X[Y==0], X[Y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x, mean, std):\n",
    "    return (1 / std * np.sqrt(PI * 2)) * np.exp(-(1 / 2) * ((x - mean) / std) * ((x - mean) / std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pdf(x, Y_A, Y_B):\n",
    "    plt.plot(x, Y_A, color='red', label='A')\n",
    "    plt.plot(x, Y_B, color='blue', label='B')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$p(x)$\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(140, 200, 1000)\n",
    "Y_A = pdf(x, np.mean(X[Y==0]), np.std(X[Y==0]))\n",
    "Y_B = pdf(x, np.mean(X[Y==1]), np.std(X[Y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pdf(x, Y_A, Y_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 2\n",
    "\n",
    "추가적으로 테스트 데이터를 샘플링해서, likelihood값만을 이용하는 경우, prior값과 결합하여 posterior로 볼 경우 각각에 대하여 분류 정확도를 보고하고 \n",
    "\n",
    "(a) likelihood 함수를 그리고, \n",
    "\n",
    "(b) prior 적용 시, likelihood x prior 함수를 그리고,\n",
    "\n",
    "(c) posterior =  likelihood x prior / p(x) 를 그리시오. \n",
    "\n",
    "prior의 변화에 따라 decision point를 그래프에서 대략적으로 읽고, prior에 따라서 분류 결과가 어떻게 변화하는지 설명하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice2_train = np.load('./practice2_train.npz')\n",
    "print(f'Check key values: {practice2_train.files}')\n",
    "X_train, Y_train = practice2_train['x'], practice2_train['y']\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice2_test = np.load('./practice2_test.npz')\n",
    "print(f'Check key values: {practice2_test.files}')\n",
    "X_test, Y_test = practice2_test['x'], practice2_test['y']\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(x, A_mean, A_std, B_mean, B_std):\n",
    "    return pdf(x, A_mean, A_std), pdf(x, B_mean, B_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(A, B):\n",
    "    prior_A = len(A)/ (len(A) + len(B))\n",
    "    return (prior_A), (1 - prior_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(x, A_likelihood, B_likelihood, A_prior, B_prior):\n",
    "    evidence = (A_likelihood * A_prior) + (B_likelihood * B_prior)\n",
    "                 \n",
    "    return A_likelihood * A_prior / evidence, B_likelihood * B_prior / evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(Y_test, A_prob, B_prob):\n",
    "    y_pred = np.where(A_prob > B_prob, 0, 1)\n",
    "\n",
    "    return len(np.where(y_pred == Y_test)[0]) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_likelihood, B_likelihood = get_likelihood(X_test, \n",
    "                                np.mean(X_train[Y_train==0]),\n",
    "                                np.std(X_train[Y_train==0]),\n",
    "                                np.mean(X_train[Y_train==1]),\n",
    "                                np.std(X_train[Y_train==1]))\n",
    "\n",
    "y_pred = np.where(A_likelihood > B_likelihood, 0, 1)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_likelihood, B_likelihood)}')\n",
    "\n",
    "graph_x = np.linspace(140, 200, 1000)\n",
    "A_graph_x, B_graph_x = get_likelihood(graph_x, \n",
    "                                np.mean(X_train[Y_train==0]),\n",
    "                                np.std(X_train[Y_train==0]),\n",
    "                                np.mean(X_train[Y_train==1]),\n",
    "                                np.std(X_train[Y_train==1]))\n",
    "show_pdf(graph_x, A_graph_x, B_graph_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prior, B_prior = get_prior(X_train[Y_train==0], X_train[Y_train==1])\n",
    "\n",
    "print(A_prior, B_prior)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_likelihood * A_prior, B_likelihood * B_prior)}')\n",
    "\n",
    "show_pdf(graph_x, A_graph_x * A_prior, B_graph_x * B_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prob, B_prob = get_posterior(X_test, A_likelihood, B_likelihood, A_prior, B_prior)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_prob, B_prob)}')\n",
    "\n",
    "A_graph_prob, B_graph_prob = get_posterior(X_test, A_graph_x, B_graph_x, A_prior, B_prior)\n",
    "\n",
    "\n",
    "show_pdf(graph_x, A_graph_prob, B_graph_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prior_A: 0.5\n",
    "- prior_B: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prob, B_prob = get_posterior(X_test, A_likelihood, B_likelihood, 0.5, 0.5)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_prob, B_prob)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prior_A: 0.4\n",
    "- prior_B: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prob, B_prob = get_posterior(X_test, A_likelihood, B_likelihood, 0.4, 0.6)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_prob, B_prob)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prior_A: 0.25\n",
    "- prior_B: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prob, B_prob = get_posterior(X_test, A_likelihood, B_likelihood, 0.25, 0.75)\n",
    "\n",
    "print(f'Acc: {get_accuracy(Y_test, A_prob, B_prob)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "위에서 prior probability를 0.5:0.5에서 0.25:0.75로 변화시키면서 Bayesian 분류기의 분류 정확도를 평가하였다.\n",
    "세가지 경우에서 점점 정확도가 떨어지는 이유에 대하여 설명하시오. \n",
    "\n",
    "답 :  \n",
    "테스트 데이터셋의 샘플 ratio는 __0.5:0.5(class 0: class 1)__ 이다.\n",
    "따라서 특정 클래스의 발생 빈도(클래스의 확률)를 나타내는 prior probability가 0.5:0.5에서 0.25:0.75로 점점 변화된다는 것은, __실제 테스트 데이터셋의 샘플 분포와 점점 달라진다는 것을 의미한다.__  \n",
    "Prior knowledge가 실제 데이터를 잘 반영하지 못하게 되기 때문에 정확도가 점점 떨어지게 되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test set ratio: {}:{}\".format(len(Y_test[Y_test == 0]) / len(Y_test),len(Y_test[Y_test == 1]) / len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 3\n",
    "두 클래스의 평균 사이의 거리를 점차 증가시키면서 train, test 데이터를 샘플링하여 Bayesian 분류기의 정확도를 계산해보시오.\n",
    "\n",
    "s = 3\n",
    "mu = (-1, 1), (-2, 2), (-3, 3)\n",
    "train / test sampling - report performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num_data, ratio, A_mean, A_std, B_mean, B_std):\n",
    "\n",
    "    num_data_A = int(num_data * ratio)\n",
    "    num_data_B = num_data - num_data_A\n",
    "\n",
    "    A = np.random.normal(loc=A_mean, scale=A_std, size=num_data_A)\n",
    "    B = np.random.normal(loc=B_mean, scale=B_std, size=num_data_B)\n",
    "    label_zeros = np.zeros((num_data_A, 1))\n",
    "    label_ones = np.ones((num_data_B, 1))\n",
    "    \n",
    "    return A, B, label_zeros, label_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -1, 3, 1, 3)\n",
    "# Test data\n",
    "test_A, test_B, test_YA, test_YB = get_data(100, 0.5, -1, 3, 1, 3)\n",
    "test_X = np.concatenate((test_A, test_B))\n",
    "test_Y = np.concatenate((test_YA, test_YB)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_likelihood, B_likelihood = get_likelihood(test_X, \n",
    "                                np.mean(train_A),\n",
    "                                np.std(train_A),\n",
    "                                np.mean(train_B),\n",
    "                                np.std(train_B))\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_prob, B_prob = get_posterior(test_X, A_likelihood, B_likelihood, A_prior, B_prior)\n",
    "print(f'Acc: {get_accuracy(test_Y, A_prob, B_prob)}')\n",
    "show_histogram(train_A, train_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -2, 3, 2, 3)\n",
    "# Test data\n",
    "test_A, test_B, test_YA, test_YB = get_data(100, 0.5, -2, 3, 2, 3)\n",
    "test_X = np.concatenate((test_A, test_B))\n",
    "test_Y = np.concatenate((test_YA, test_YB)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_likelihood, B_likelihood = get_likelihood(test_X, \n",
    "                                np.mean(train_A),\n",
    "                                np.std(train_A),\n",
    "                                np.mean(train_B),\n",
    "                                np.std(train_B))\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_prob, B_prob = get_posterior(test_X, A_likelihood, B_likelihood, A_prior, B_prior)\n",
    "print(f'Acc: {get_accuracy(test_Y, A_prob, B_prob)}')\n",
    "show_histogram(train_A, train_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -3, 3, 3, 3)\n",
    "# Test data\n",
    "test_A, test_B, test_YA, test_YB = get_data(100, 0.5, -3, 3, 3, 3)\n",
    "test_X = np.concatenate((test_A, test_B))\n",
    "test_Y = np.concatenate((test_YA, test_YB)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_likelihood, B_likelihood = get_likelihood(test_X, \n",
    "                                np.mean(train_A),\n",
    "                                np.std(train_A),\n",
    "                                np.mean(train_B),\n",
    "                                np.std(train_B))\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_prob, B_prob = get_posterior(test_X, A_likelihood, B_likelihood, A_prior, B_prior)\n",
    "print(f'Acc: {get_accuracy(test_Y, A_prob, B_prob)}')\n",
    "show_histogram(train_A, train_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 4\n",
    "\n",
    "Practice 3에서 그린 세 개의 히스토그램을 probability density function으로 그리시오.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pdf(x, Y_A, Y_B, title=\"\"):\n",
    "    plt.plot(x, Y_A, color='red', label='A')\n",
    "    plt.plot(x, Y_B, color='blue', label='B')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$p(x)$\")\n",
    "    plt.title(\"{}\".format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 먼저 Practice 3과 동일한 mean과 standard deviation을 가지는 1000개의 train 데이터셋을 만든다.\n",
    "2. Train 데이터셋의 min값과 max값을 구하여 그래프를 그릴 x의 range를 구한다.\n",
    "3. 2에서 구한 x의 범위에 대하여 train_A와 train_B의 mean과 std을 통해 probability density 값을 구한다.\n",
    "4. 그래프를 그린다.\n",
    "\"\"\"\n",
    "# Train data set 만들기\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -1, 3, 1, 3)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# Train data의 X 범위 구하기\n",
    "train_min = train_X.min() - 1\n",
    "train_max = train_X.max() + 1\n",
    "\n",
    "# 그래프를 그릴 x의 값 구하기(1000개)\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# probability density 값 구하기\n",
    "# mean과 std 값으로 위의 train data set을 만들 때 사용한 값을 그대로 사용해도 되지만,\n",
    "# 실제 만들어진 data의 값과 약간의 차이가 있으므로 직접 구한 mean과 std를 사용한다.\n",
    "A_pdf = pdf(graph_x, np.mean(train_A), np.std(train_A))\n",
    "B_pdf = pdf(graph_x, np.mean(train_B), np.std(train_B))\n",
    "\n",
    "# 그래프 그리기\n",
    "show_pdf(graph_x, A_pdf, B_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 먼저 Practice 3과 동일한 mean과 standard deviation을 가지는 1000개의 train 데이터셋을 만든다.\n",
    "2. Train 데이터셋의 min값과 max값을 구하여 그래프를 그릴 x의 range를 구한다.\n",
    "3. 2에서 구한 x의 범위에 대하여 train_A와 train_B의 mean과 std을 통해 probability density 값을 구한다.\n",
    "4. 그래프를 그린다.\n",
    "\"\"\"\n",
    "# Train data set 만들기\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -2, 3, 2, 3)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# Train data의 X 범위 구하기\n",
    "train_min = train_X.min() - 1\n",
    "train_max = train_X.max() + 1\n",
    "\n",
    "# 그래프를 그릴 x의 값 구하기(1000개)\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# probability density 값 구하기\n",
    "# mean과 std 값으로 위의 train data set을 만들 때 사용한 값을 그대로 사용해도 되지만,\n",
    "# 실제 만들어진 data의 값과 약간의 차이가 있으므로 직접 구한 mean과 std를 사용한다.\n",
    "A_pdf = pdf(graph_x, np.mean(train_A), np.std(train_A))\n",
    "B_pdf = pdf(graph_x, np.mean(train_B), np.std(train_B))\n",
    "\n",
    "# 그래프 그리기\n",
    "show_pdf(graph_x, A_pdf, B_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 먼저 Practice 3과 동일한 mean과 standard deviation을 가지는 1000개의 train 데이터셋을 만든다.\n",
    "2. Train 데이터셋의 min값과 max값을 구하여 그래프를 그릴 x의 range를 구한다.\n",
    "3. 2에서 구한 x의 범위에 대하여 train_A와 train_B의 mean과 std을 통해 probability density 값을 구한다.\n",
    "4. 그래프를 그린다.\n",
    "\"\"\"\n",
    "# Train data set 만들기\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -3, 3, 3, 3)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# Train data의 X 범위 구하기\n",
    "train_min = train_X.min() - 1\n",
    "train_max = train_X.max() + 1\n",
    "\n",
    "# 그래프를 그릴 x의 값 구하기(1000개)\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# probability density 값 구하기\n",
    "# mean과 std 값으로 위의 train data set을 만들 때 사용한 값을 그대로 사용해도 되지만,\n",
    "# 실제 만들어진 data의 값과 약간의 차이가 있으므로 직접 구한 mean과 std를 사용한다.\n",
    "A_pdf = pdf(graph_x, np.mean(train_A), np.std(train_A))\n",
    "B_pdf = pdf(graph_x, np.mean(train_B), np.std(train_B))\n",
    "\n",
    "# 그래프 그리기\n",
    "show_pdf(graph_x, A_pdf, B_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 5\n",
    "\n",
    "두 클래스의 데이터가 다음과 같은 Gaussian 분포를 따른다고 할 때, 아래 설명에 따라 Bayesian 분류기의 분류 정확도를 계산하시오. \n",
    "\n",
    "A class : mu = -1, s = 3\n",
    "B class : mu = 3, s = 2\n",
    "\n",
    "a) P(A)=P(B)일 때, p(x|A), p(x|B), P(A|x), P(B|x)를 그리시오.\n",
    "\n",
    "b) P(A)=1/3, P(B)=2/3일 때, p(x|A), p(x|B), P(A|x), P(B|x)를 그리시오.\n",
    "\n",
    "c) a)와 b)에서 구한 p(A|x)=p(B|x)을 풀면 decision point를 구할 수 있다. 각 decision point를 구하여 a)와 b)에서 그린 그래프 위에 표시하시오. \n",
    "\n",
    "d) Decision point를 구한 후에 Bayesian 분류기의 분류 방법이 어떻게 간단히 변화할 수 있는지 설명하시오.\n",
    "\n",
    "e) test set을 A, B 클래스에 대하여 각 100개씩 샘플링하여, d)에서 설명한 방법으로 분류 정확도를 구하시오. 단, P(A)=P(B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) P(A)=P(B)일 때, p(x|A), p(x|B), P(A|x), P(B|x)를 그리시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 만들기\n",
    "# A class : mu = -1, s = 3 B class : mu = 3, s = 2\n",
    "# P(A)=P(B)일 때, P(A)=P(B)=0.5(prior probability)이다.\n",
    "# get_data 함수를 사용하여 만든다.\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -1, 3, 3, 2)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# 위에서 만든 데이터셋의 min과 max값을 사용하여 그래프를 그릴 x의 값(1000개)을 구한다.\n",
    "train_min = train_X.min() - 10\n",
    "train_max = train_X.max() + 10\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# get_likelihood 함수를 통해 likelihood(p(x|A)와 p(x|B))를 구한다.\n",
    "A_graph_x, B_graph_x = get_likelihood(graph_x, np.mean(train_A),\n",
    "                                      np.std(train_A), np.mean(train_B),\n",
    "                                      np.std(train_B))\n",
    "# p(x|A)와 p(x|B)를 그린다.\n",
    "show_pdf(graph_x, A_graph_x, B_graph_x, \"p(x|A), p(x|B)\")\n",
    "\n",
    "# get_posterior 함수를 통해 posterior(P(A|x), P(B|x))를 구한다.\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_graph_prob, B_graph_prob = get_posterior(graph_x, A_graph_x, B_graph_x,\n",
    "                                           A_prior, B_prior)\n",
    "\n",
    "# P(A|x), P(B|x)를 그린다.\n",
    "show_pdf(graph_x, A_graph_prob, B_graph_prob, \"P(A|x), P(B|x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) P(A)=1/3, P(B)=2/3일 때, p(x|A), p(x|B), P(A|x), P(B|x)를 그리시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기\n",
    "# A class : mu = -1, s = 3 B class : mu = 3, s = 2\n",
    "# P(A)=1/3, P(B)=2/3\n",
    "# get_data 함수를 사용하여 만든다.\n",
    "train_A, train_B, _, _ = get_data(1000, 1 / 3, -1, 3, 3, 2)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# 위에서 만든 데이터셋의 min과 max값을 사용하여 그래프를 그릴 x의 값(1000개)을 구한다.\n",
    "train_min = train_X.min() - 10\n",
    "train_max = train_X.max() + 10\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# get_likelihood 함수를 통해 likelihood(p(x|A)와 p(x|B))를 구한다.\n",
    "A_graph_x, B_graph_x = get_likelihood(graph_x, np.mean(train_A),\n",
    "                                      np.std(train_A), np.mean(train_B),\n",
    "                                      np.std(train_B))\n",
    "# p(x|A)와 p(x|B)를 그린다.\n",
    "show_pdf(graph_x, A_graph_x, B_graph_x, \"p(x|A), p(x|B)\")\n",
    "\n",
    "# get_posterior 함수를 통해 posterior(P(A|x), P(B|x))를 구한다.\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_graph_prob, B_graph_prob = get_posterior(graph_x, A_graph_x, B_graph_x,\n",
    "                                           A_prior, B_prior)\n",
    "\n",
    "# P(A|x), P(B|x)를 그린다.\n",
    "show_pdf(graph_x, A_graph_prob, B_graph_prob, \"P(A|x), P(B|x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) a)와 b)에서 구한 p(A|x)=p(B|x)을 풀면 decision point를 구할 수 있다. 각 decision point를 구하여 a)와 b)에서 그린 그래프 위에 표시하시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pdf_with_decision_point(x,\n",
    "                                 Y_A,\n",
    "                                 Y_B,\n",
    "                                 decision_point_x,\n",
    "                                 decision_point_y,\n",
    "                                 title=\"\"):\n",
    "    plt.plot(x, Y_A, color='red', label='A')\n",
    "    plt.plot(x, Y_B, color='blue', label='B')\n",
    "    plt.scatter(decision_point_x,\n",
    "                decision_point_y,\n",
    "                color='black',\n",
    "                label=\"Decision point\")\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$p(x)$\")\n",
    "    plt.title(\"{}\".format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_decision_point(A_mean, A_std, B_mean, B_std):\n",
    "#     if A_std==B_std:\n",
    "#         x1 = (A_mean+B_mean)/2\n",
    "#         x2 = (A_mean+B_mean)/2\n",
    "#     else:\n",
    "#         x1 = (-(B_std * B_std * A_mean - A_std * A_std * B_mean) + np.sqrt(\n",
    "#             (B_std * B_std * A_mean - A_std * A_std * B_mean) *\n",
    "#             (B_std * B_std * A_mean - A_std * A_std * B_mean) -\n",
    "#             (A_std * A_std * B_mean * B_mean - B_std * B_std * A_mean * A_mean -\n",
    "#              2 * A_std * A_std * B_std * B_std - np.log(A_std / B_std) *\n",
    "#              (A_std * A_std - B_std * B_std)))) / (A_std * A_std - B_std * B_std)\n",
    "#         x2 = (-(B_std * B_std * A_mean - A_std * A_std * B_mean) - np.sqrt(\n",
    "#             (B_std * B_std * A_mean - A_std * A_std * B_mean) *\n",
    "#             (B_std * B_std * A_mean - A_std * A_std * B_mean) -\n",
    "#             (A_std * A_std * B_mean * B_mean - B_std * B_std * A_mean * A_mean -\n",
    "#              2 * A_std * A_std * B_std * B_std - np.log(A_std / B_std) *\n",
    "#              (A_std * A_std - B_std * B_std)))) / (A_std * A_std - B_std * B_std)\n",
    "#     return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기\n",
    "# A class : mu = -1, s = 3 B class : mu = 3, s = 2\n",
    "# P(A)=P(B)일 때, P(A)=P(B)=0.5(prior probability)이다.\n",
    "# get_data 함수를 사용하여 만든다.\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -1, 3, 3, 2)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# 위에서 만든 데이터셋의 min과 max값을 사용하여 그래프를 그릴 x의 값(1000개)을 구한다.\n",
    "train_min = train_X.min() - 10\n",
    "train_max = train_X.max() + 10\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# get_likelihood 함수를 통해 likelihood(p(x|A)와 p(x|B))를 구한다.\n",
    "A_graph_x, B_graph_x = get_likelihood(graph_x, np.mean(train_A),\n",
    "                                      np.std(train_A), np.mean(train_B),\n",
    "                                      np.std(train_B))\n",
    "\n",
    "# get_posterior 함수를 통해 posterior(P(A|x), P(B|x))를 구한다.\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_graph_prob, B_graph_prob = get_posterior(graph_x, A_graph_x, B_graph_x,\n",
    "                                           A_prior, B_prior)\n",
    "\n",
    "# decision point를 구한다.\n",
    "# A_graph_prob와 B_graph_prob이 값들이 point로 이루어져있기 때문에, 현재 생성한 데이터에는 완전히 똑같은 값이 존재하지 않을 수 있다.\n",
    "# A_graph_prob와 B_graph_prob들을 round 해주어 동일한 값이 나오도록 한다.\n",
    "# round로 인해 한 지점에서 한 개 이상의 decision point가 생길 수 있다.\n",
    "\n",
    "# p(A|x)=p(B|x)일 때의 x값과 posterior probability값을 구한다.\n",
    "decision_point_x = graph_x[np.round_(A_graph_prob, 2) == np.round_(\n",
    "    B_graph_prob, 2)]  # 소수점 두 자릿수까지 round한다.\n",
    "# decision_point_y = A_graph_x[np.round_(A_graph_prob,2) == np.round_(B_graph_prob,2)]\n",
    "decision_point_prob_y = A_graph_prob[np.round_(A_graph_prob, 2) == np.round_(\n",
    "    B_graph_prob, 2)]\n",
    "\n",
    "# decision point를 그린다.\n",
    "# show_pdf_with_decision_point(graph_x, A_graph_x, B_graph_x,decision_point_x, decision_point_y, \"p(x|A), p(x|B) with decision point\")\n",
    "show_pdf_with_decision_point(graph_x, A_graph_prob, B_graph_prob,\n",
    "                             decision_point_x, decision_point_prob_y,\n",
    "                             \"P(A|x), P(B|x) with decision point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기\n",
    "# A class : mu = -1, s = 3 B class : mu = 3, s = 2\n",
    "# P(A)=1/3, P(B)=2/3\n",
    "# get_data 함수를 사용하여 만든다.\n",
    "train_A, train_B, _, _ = get_data(1000, 1 / 3, -1, 3, 3, 2)\n",
    "train_X = np.concatenate((train_A, train_B))\n",
    "\n",
    "# 위에서 만든 데이터셋의 min과 max값을 사용하여 그래프를 그릴 x의 값(1000개)을 구한다.\n",
    "train_min = train_X.min() - 10\n",
    "train_max = train_X.max() + 10\n",
    "graph_x = np.linspace(train_min, train_max, 1000)\n",
    "\n",
    "# get_likelihood 함수를 통해 likelihood(p(x|A)와 p(x|B))를 구한다.\n",
    "A_graph_x, B_graph_x = get_likelihood(graph_x, np.mean(train_A),\n",
    "                                      np.std(train_A), np.mean(train_B),\n",
    "                                      np.std(train_B))\n",
    "\n",
    "# get_posterior 함수를 통해 posterior(P(A|x), P(B|x))를 구한다.\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_graph_prob, B_graph_prob = get_posterior(graph_x, A_graph_x, B_graph_x,\n",
    "                                           A_prior, B_prior)\n",
    "\n",
    "# decision point를 구한다.\n",
    "# A_graph_prob와 B_graph_prob이 값들이 point로 이루어져있기 때문에, 현재 생성한 데이터에는 완전히 똑같은 값이 존재하지 않을 수 있다.\n",
    "# A_graph_prob와 B_graph_prob들을 round 해주어 동일한 값이 나오도록 한다.\n",
    "# round로 인해 한 지점에서 한 개 이상의 decision point가 생길 수 있다.\n",
    "\n",
    "# p(A|x)=p(B|x)일 때의 x값과 posterior probability값을 구한다.\n",
    "decision_point_x = graph_x[np.round_(A_graph_prob, 2) == np.round_(\n",
    "    B_graph_prob, 2)]  # 소수점 두 자릿수까지 round한다.\n",
    "# decision_point_y = A_graph_x[np.round_(A_graph_prob,2) == np.round_(B_graph_prob,2)]\n",
    "decision_point_prob_y = A_graph_prob[np.round_(A_graph_prob, 2) == np.round_(\n",
    "    B_graph_prob, 2)]\n",
    "\n",
    "# decision point를 그린다.\n",
    "# show_pdf_with_decision_point(graph_x, A_graph_x, B_graph_x,decision_point_x, decision_point_y, \"p(x|A), p(x|B) with decision point\")\n",
    "show_pdf_with_decision_point(graph_x, A_graph_prob, B_graph_prob,\n",
    "                             decision_point_x, decision_point_prob_y,\n",
    "                             \"P(A|x), P(B|x) with decision point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Decision point를 구한 후에 Bayesian 분류기의 분류 방법이 어떻게 간단히 변화할 수 있는지 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__방법1:__ Decision point를 기준으로 x의 클래스 분류 값이 달라지게 된다. 따라서 decision point를 구한 후, 값들을 기준으로 클래스를 분류할 수 있다. 위 예제에서 첫 번째 decision point 전까지는 class A, 첫 번째 decision point와 두 번째 decision point사이에는 class B, 두 번째 decision point 이후엔 class A로 분류한다.  \n",
    "\n",
    "__방법2:__ Decision point의 값은 0.5이다. 따라서 posterior probability값이 0.5보다 크면 그 클래스로, 0.5보다 작으면 다른 클래스로 분류하는 방법도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) test set을 A, B 클래스에 대하여 각 100개씩 샘플링하여, d)에서 설명한 방법으로 분류 정확도를 구하시오. 단, P(A)=P(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기\n",
    "# A class : mu = -1, s = 3 B class : mu = 3, s = 2\n",
    "# P(A)=P(B)=0.5\n",
    "# get_data 함수를 사용하여 만든다.\n",
    "# Train data\n",
    "train_A, train_B, _, _ = get_data(1000, 0.5, -1, 3, 3, 2)\n",
    "# Test data(A, B 클래스에 대하여 각 100개씩, 총 200개)\n",
    "test_A, test_B, test_YA, test_YB = get_data(200, 0.5, -1, 3, 3, 2)\n",
    "test_X = np.concatenate((test_A, test_B))\n",
    "test_Y = np.concatenate((test_YA, test_YB)).reshape(-1)\n",
    "\n",
    "# posterior probability(P(A|x), P(B|x))를 구한다.\n",
    "A_likelihood, B_likelihood = get_likelihood(test_X, np.mean(train_A),\n",
    "                                            np.std(train_A), np.mean(train_B),\n",
    "                                            np.std(train_B))\n",
    "A_prior, B_prior = get_prior(train_A, train_B)\n",
    "A_prob, B_prob = get_posterior(test_X, A_likelihood, B_likelihood, A_prior,\n",
    "                               B_prior)\n",
    "\n",
    "# decision point를 구한다.\n",
    "# A_graph_prob와 B_graph_prob이 값들이 point로 이루어져있기 때문에, 현재 생성한 데이터에는 완전히 똑같은 값이 존재하지 않는다.\n",
    "# A_graph_prob와 B_graph_prob들을 round 해주어 동일한 값이 나오도록 한다.\n",
    "# round로 인해 한 개 이상의 decision point가 생길 수 있다.\n",
    "decision_point = test_X[np.round_(A_prob,\n",
    "                                  1) == np.round_(B_prob,\n",
    "                                                  1)]  # 소수점 한 자릿수까지 round한다.\n",
    "\n",
    "# 방법1: decision point를 기준으로 test_X를 분류한다.\n",
    "y_pred1 = np.where(test_X < decision_point[0], 0, 1)\n",
    "accuracy1 = len(np.where(y_pred1 == test_Y)[0]) / len(y_pred1)\n",
    "print(\"방법 1 분류 정확도: {}\".format(accuracy1))\n",
    "\n",
    "# 방법2: posterior probability값 0.5을 기준으로, A_prob의 값에 따라 분류한다.\n",
    "y_pred2 = np.where(A_prob >= 0.5, 0, 1)\n",
    "accuracy2 = len(np.where(y_pred2 == test_Y)[0]) / len(y_pred2)\n",
    "print(\"방법 2 분류 정확도: {}\".format(accuracy2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
